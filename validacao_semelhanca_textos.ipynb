{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e987a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145ad743",
   "metadata": {},
   "source": [
    "## Validando modelos\n",
    "Um pequeno racional para vermos o comportamento dos modelos:\n",
    "\n",
    "    1- Vetorização e similaridade a partir do cosseno, varia de -1 a 1, \n",
    "        - valores próximos de 0: diferentes, \n",
    "        - perto de 1: similares \n",
    "    é um modelo que não considera relações semânticas mais complexas, \n",
    "    valida a presença ou ausência das palavras a partir do texto vetorizado\n",
    "    \n",
    "    2 - Embeddings de frases (BERT): utiliza um modelo pré-treinado para gerar os embeddings\n",
    "        de frases que capturam a semântica dos textos, logo considera contexto semântico,\n",
    "        - valores próximos de 1: Textos são semanticamente idênticos.\n",
    "        - 0: Textos não têm similaridade semântica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d775fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textos a serem comparados\n",
    "texto1 = \"Este é o primeiro texto.\"\n",
    "texto2 = \"Este é o texto primeiro.\"\n",
    "\n",
    "texto3 = \"texto sem nada igual ao outro\"\n",
    "texto4 = \"validando vetorização\"\n",
    "\n",
    "# Vetorização dos textos\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform([texto1, texto2])\n",
    "\n",
    "# Cálculo da similaridade cosseno\n",
    "similaridade = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "\n",
    "print(f\"A similaridade entre os textos parecidos é: {similaridade[0][0]:.2f}\")\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform([texto3, texto4])\n",
    "similaridade = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "\n",
    "print(f\"A similaridade entre os textos diferentes é: {similaridade[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo de embeddings de frases\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Textos a serem comparados\n",
    "texto1 = \"Este é o primeiro texto.\"\n",
    "texto2 = \"Este é o texto primeiro.\"\n",
    "\n",
    "texto3 = \"texto sem nada igual ao outro\"\n",
    "texto4 = \"validando vetorização\"\n",
    "\n",
    "# Gerar embeddings para os textos\n",
    "embedding1 = model.encode(texto1, convert_to_tensor=True)\n",
    "embedding2 = model.encode(texto2, convert_to_tensor=True)\n",
    "\n",
    "# Calcular a similaridade cosseno entre os embeddings\n",
    "similaridade = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "\n",
    "print(f\"A similaridade entre os textos é: {similaridade.item():.2f}\")\n",
    "\n",
    "embedding3 = model.encode(texto3, convert_to_tensor=True)\n",
    "embedding4 = model.encode(texto4, convert_to_tensor=True)\n",
    "\n",
    "# Calcular a similaridade cosseno entre os embeddings\n",
    "similaridade = util.pytorch_cos_sim(embedding3, embedding4)\n",
    "\n",
    "print(f\"A similaridade entre os textos é: {similaridade.item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4106a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a similaridade cosseno com TF-IDF\n",
    "def calcular_similaridade_tfidf(text1, text2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
    "    similaridade = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    return similaridade[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c73f1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a similaridade com BERT\n",
    "def calcular_similaridade_bert(text1, text2):\n",
    "    embedding1 = model.encode(text1, convert_to_tensor=True)\n",
    "    embedding2 = model.encode(text2, convert_to_tensor=True)\n",
    "    similaridade = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    return similaridade.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e99dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('resultado.csv', sep=\";\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec845c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas para armazenar as similaridades\n",
    "similaridades_tfidf = []\n",
    "similaridades_bert = []\n",
    "\n",
    "# Iterar sobre as linhas do DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    text1 = row['resposta_DF']\n",
    "    text2 = row['resposta_genPlat']\n",
    "    \n",
    "    # Calcular similaridades\n",
    "    sim_tfidf = calcular_similaridade_tfidf(text1, text2)\n",
    "    sim_bert = calcular_similaridade_bert(text1, text2)\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    similaridades_tfidf.append(sim_tfidf)\n",
    "    similaridades_bert.append(sim_bert)\n",
    "    \n",
    "# Adicionar as novas colunas ao DataFrame\n",
    "df['similaridade_tfidf'] = similaridades_tfidf\n",
    "df['similaridade_bert'] = similaridades_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98045ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificar_similaridade(row):\n",
    "    sim_tfidf = row['similaridade_tfidf']\n",
    "    sim_bert = row['similaridade_bert']\n",
    "    \n",
    "    if sim_tfidf > 0.7 and sim_bert > 0.7:\n",
    "        return \"Conteúdo semelhante - 2 métricas\"\n",
    "    elif sim_tfidf > 0.7 or sim_bert > 0.7:\n",
    "        return \"Conteúdo semelhante - 1 métrica\"\n",
    "    elif (0.5 < sim_tfidf <= 0.7) or (0.5 < sim_bert <= 0.7):\n",
    "        return \"Validação humana\"\n",
    "    else:\n",
    "        return \"Nenhuma das métricas encontrou semelhança maior que 0.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2689e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a função ao DataFrame para criar a nova coluna\n",
    "df['classificacao'] = df.apply(classificar_similaridade, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff93ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir o novo DataFrame\n",
    "df.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
